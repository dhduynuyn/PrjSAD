import os
import pickle
import faiss
import numpy as np
import psycopg2
from dotenv import load_dotenv
from sklearn.preprocessing import normalize
from sentence_transformers import SentenceTransformer
import sys
import os

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__))))

from gen_reanswer_from_AI import gen_response
load_dotenv()

# ========== CONFIG ========== 
DB_CONFIG = {
    "dbname": os.getenv('DB_NAME'),
    "user": os.getenv('DB_USER'),
    "password": os.getenv('DB_PASSWORD'),
    "host": os.getenv('DB_HOST'),
    "port": os.getenv('DB_PORT')
}

EMBEDDING_FILE = "story_embeddings.pkl"
INDEX_FILE = "story_faiss.index"
MODEL_NAME = "keepitreal/vietnamese-sbert"

# ========== LOAD MODEL ========== 
model = SentenceTransformer(MODEL_NAME)

# ========== LOAD DATA FROM DATABASE ========== 
def fetch_story_data():
    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()
    cur.execute("""SELECT id, title, description, summary, genres
                FROM public."Story"; """)  # C·∫≠p nh·∫≠t query ƒë·ªÉ l·∫•y th√™m c·ªôt 'genres'
    rows = cur.fetchall()
    conn.close()
    return rows

# ========== EMBEDDING ========== 
def create_texts_and_embeddings(data):
    texts = []
    embeddings = []

    for row in data:
        _, title, description, summary, genre = row
        title = title or ""
        description = description or ""
        summary = summary or ""  # ƒê·∫£m b·∫£o summary ƒë∆∞·ª£c s·ª≠ d·ª•ng
        genre = genre or ""

        # K·∫øt h·ª£p genre, title, description, summary v√†o full_text
        full_text = f"{genre}. {title}. {description}. {summary}"
        try:
            emb = model.encode([full_text])[0]  # Tr·∫£ v·ªÅ vector 1D
            texts.append((full_text, summary, genre))  # L∆∞u c·∫£ full_text, summary v√† genre
            embeddings.append(emb)
        except Exception as e:
            print(f"‚ö†Ô∏è B·ªè qua v√¨ l·ªói encode: {title}\n{e}")

    return texts, np.array(embeddings, dtype=np.float32)

# ========== SAVE ========== 
def save_index_and_data(index, texts):
    faiss.write_index(index, INDEX_FILE)
    with open(EMBEDDING_FILE, "wb") as f:
        pickle.dump(texts, f)

# ========== LOAD ========== 
def load_index_and_data():
    if not os.path.exists(INDEX_FILE) or not os.path.exists(EMBEDDING_FILE):
        return None, None
    index = faiss.read_index(INDEX_FILE)
    with open(EMBEDDING_FILE, "rb") as f:
        texts = pickle.load(f)
    return index, texts

# ========== BUILD VECTOR DB ========== 
def build_index(embeddings):
    dim = embeddings.shape[1]
    index = faiss.IndexFlatL2(dim)
    index.add(embeddings)
    return index
    

# ========== MAIN ========== 
def setup():
    index, texts = load_index_and_data()
    if index is not None and texts is not None:
        print("‚úÖ ƒê√£ load index v√† embedding t·ª´ file.")
        return index, texts

    print("üì• ƒêang l·∫•y d·ªØ li·ªáu t·ª´ PostgreSQL...")
    data = fetch_story_data()
    texts, embeddings = create_texts_and_embeddings(data)
    index = build_index(embeddings)
    save_index_and_data(index, texts)
    print("‚úÖ ƒê√£ t·∫°o v√† l∆∞u index m·ªõi.")
    return index, texts

def gen_query(user_want, answer):
    prompt = (
        "ƒê√¢y l√† m·ªôt cu·ªôc tr√≤ chuy·ªán, trong ƒë√≥ ng∆∞·ªùi d√πng ƒëang t√¨m truy·ªán ƒë·ªÉ ƒë·ªçc.\n"
        "ƒê√¢y l√† c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: " f"{user_want}\n\n"
        "H·ªá th·ªëng ƒë√£ t√¨m ƒë∆∞·ª£c m·ªôt s·ªë truy·ªán ph√π h·ª£p th√¥ng qua truy v·∫•n embedding.\n\n"
        "Nhi·ªám v·ª• c·ªßa b·∫°n l√†: Vi·∫øt l·∫°i m·ªôt c√¢u tr·∫£ l·ªùi ph√π h·ª£p v·ªõi ng∆∞·ªùi d√πng, gi·ªõi thi·ªáu truy·ªán m·ªôt c√°ch t·ª± nhi√™n, "
        "kh√¥ng qu√° d√†i d√≤ng, v√† ch·ªâ gi·ªõi thi·ªáu nh·ªØng truy·ªán b·∫°n nghƒ© ph√π h·ª£p nh·∫•t do model emdedding c√≤n kh√° nhi·ªÅu l·ªói.\n"
        "\n\n"
        f"D∆∞·ªõi ƒë√¢y l√† k·∫øt qu·∫£ truy v·∫•n:\n{answer}\n\n"
        "H√£y t·∫°o ra m·ªôt ƒëo·∫°n ph·∫£n h·ªìi m·∫°ch l·∫°c, th√¢n thi·ªán v√† ph√π h·ª£p ng·ªØ c·∫£nh h·ªôi tho·∫°i."
    )
    return prompt

# ========== CHAT ========== 
index, texts = setup()

def chat(query):
    # T√≠nh to√°n embedding cho title, description, summary v√† genre c·ªßa truy v·∫•n
    emb_title = model.encode(query)
    emb_desc = model.encode(query)
    emb_summary = model.encode(query)
    emb_genre = model.encode(query)

    # T·ªïng h·ª£p c√°c vector v·ªõi tr·ªçng s·ªë cho genre, summary, description v√† title
    query_vector = emb_title + emb_desc + 3 * emb_summary + 2 * emb_genre
    query_vector = np.array([query_vector]).astype("float32")

    # T√¨m ki·∫øm trong index
    D, I = index.search(query_vector, k=15)
    user_want = query.strip().lower()
    answer = "üìö G·ª£i √Ω truy·ªán ph√π h·ª£p:"
    for i in I[0]:
        full_text, summary, genre = texts[i]
        answer += f"üëâ T√≥m t·∫Øt: {summary}\n üîñ Th·ªÉ lo·∫°i: {genre}\n"

        
    print(answer)
    query = gen_query(user_want, answer)
    AI_answer = gen_response(query)
    print(f"ü§ñ AI tr·∫£ l·ªùi: {AI_answer}")
    return AI_answer

# ========== RUN ========== 
# if __name__ == "__main__":
    
#     chat(index, texts)
