import psycopg2
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import pickle
import os
from dotenv import load_dotenv
from sklearn.preprocessing import normalize

load_dotenv()

# Load mÃ´ hÃ¬nh embedding
model = SentenceTransformer("keepitreal/vietnamese-sbert")

# Táº­p cÃ¡c tá»« khÃ³a liÃªn quan
KEYWORDS = [
    "BÃ¡ch Há»£p", "BE", "Chá»¯a LÃ nh", "Cá»• Äáº¡i", "Cung Äáº¥u", "CÆ°á»›i TrÆ°á»›c YÃªu Sau",
    "CÆ°á»ng Thá»§ HÃ o Äoáº¡t", "Dá»‹ NÄƒng", "DÆ°á»¡ng ThÃª", "Äam Má»¹", "Äiá»n VÄƒn", "ÄÃ´ Thá»‹",
    "Äoáº£n VÄƒn", "Äá»c TÃ¢m", "Gáº£ Thay", "Gia Äáº¥u", "Gia ÄÃ¬nh", "GÆ°Æ¡ng Vá»¡ KhÃ´ng LÃ nh",
    "GÆ°Æ¡ng Vá»¡ Láº¡i LÃ nh", "HÃ i HÆ°á»›c", "HÃ nh Äá»™ng", "HÃ o MÃ´n Tháº¿ Gia", "HE", "Há»‡ Thá»‘ng",
    "Hiá»‡n Äáº¡i", "HoÃ¡n Äá»•i ThÃ¢n XÃ¡c", "Há»c BÃ¡", "Há»c ÄÆ°á»ng", "HÆ° Cáº¥u Ká»³ áº¢o", "Huyá»n Huyá»…n",
    "KhÃ´ng CP", "Kinh Dá»‹", "Linh Dá»‹", "Máº¡t Tháº¿", "NgÃ´n TÃ¬nh", "Ngá»t",
    "NgÆ°á»£c", "NgÆ°á»£c Luyáº¿n TÃ n TÃ¢m", "NgÆ°á»£c Nam", "NgÆ°á»£c Ná»¯", "NhÃ¢n ThÃº", "NiÃªn Äáº¡i",
    "Ná»¯ CÆ°á»ng", "OE", "PhÃ©p Thuáº­t", "PhiÃªu LÆ°u", "PhÆ°Æ¡ng ÄÃ´ng", "PhÆ°Æ¡ng TÃ¢y",
    "Quy táº¯c", "Sáº£ng VÄƒn", "SE", "Showbiz", "Sá»§ng", "Thanh XuÃ¢n VÆ°á»n TrÆ°á»ng",
    "TiÃªn Hiá»‡p", "Tiá»ƒu Thuyáº¿t", "Tá»•ng TÃ i", "TrÃ  ThÃ¹", "Trinh thÃ¡m", "Trá»ng Sinh",
    "Truy ThÃª", "VÃ  Máº·t", "VÃ´ Tri", "XuyÃªn KhÃ´ng", "XuyÃªn SÃ¡ch"
]


# Káº¿t ná»‘i database
conn = psycopg2.connect(
    host=os.getenv("DB_HOST"),
    port=os.getenv("DB_PORT"),
    dbname=os.getenv("DB_NAME"),
    user=os.getenv("DB_USER"),
    password=os.getenv("DB_PASSWORD"),
    connect_timeout=int(os.getenv("DB_CONNECT_TIMEOUT", 10))
)
cursor = conn.cursor()

# Lá»c truyá»‡n cÃ³ genre phÃ¹ há»£p
def fetch_filtered_stories():
    query = f"""
        SELECT id, title, description, genres
        FROM public."Story"
    """
    cursor.execute(query)
    return cursor.fetchall()

def build_or_load_index():
    try:
        with open("filtered_story_vectors.pkl", "rb") as f:
            data = pickle.load(f)
            print("âœ… ÄÃ£ load FAISS index vÃ  metadata.")
            return data["index"], data["story_info"]
    except FileNotFoundError:
        print("ðŸ”„ Äang xÃ¢y dá»±ng FAISS index...")
        stories = fetch_filtered_stories()
        story_info = []
        embeddings = []

        for sid, title, desc, genre in stories:
            title = title.strip()
            desc = desc.strip()
            genre = genre.strip()

            # Encode tá»«ng pháº§n riÃªng láº»
            title_emb = normalize([model.encode(title)])[0]
            desc_emb = normalize([model.encode(desc)])[0]
            genre_emb = normalize([model.encode(genre)])[0]

            # Káº¿t há»£p vá»›i trá»ng sá»‘: Æ°u tiÃªn genre
            combined_emb = 2 * genre_emb + 1 * title_emb + 1 * desc_emb
            embeddings.append(combined_emb)

            story_info.append({
                "id": sid,
                "title": title,
                "description": desc,
                "genre": genre
            })

        vectors = np.array(embeddings).astype("float32")
        index = faiss.IndexFlatL2(vectors.shape[1])
        index.add(vectors)

        with open("filtered_story_vectors.pkl", "wb") as f:
            pickle.dump({"index": index, "story_info": story_info}, f)

        print("âœ… FAISS index Ä‘Ã£ Ä‘Æ°á»£c xÃ¢y dá»±ng vÃ  lÆ°u.")
        return index, story_info

# TÃ¬m kiáº¿m truyá»‡n gáº§n nháº¥t
def search(query, index, story_info, k=5):
    q_vec = model.encode([query])
    D, I = index.search(np.array(q_vec).astype("float32"), k)

    results = []
    for idx in I[0]:
        s = story_info[idx]
        results.append(s)
    return results

# Giao diá»‡n CLI Ä‘Æ¡n giáº£n
def chatbot():
    index, story_info = build_or_load_index()

    print("Báº¡n muá»‘n tÃ¬m truyá»‡n nhÆ° tháº¿ nÃ o? (nháº­p 'exit' Ä‘á»ƒ thoÃ¡t)")
    while True:
        query = input("> ").strip()
        if query.lower() == "exit":
            break

        results = search(query, index, story_info)
        print("\nðŸ“š Gá»£i Ã½ truyá»‡n phÃ¹ há»£p:")
        for res in results:
            print(f" - {res['title']}. {res['description'][:400]}... {res['genre']}\n")

chatbot()
