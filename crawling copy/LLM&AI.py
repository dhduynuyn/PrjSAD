import os
import json
import pickle
import faiss
import numpy as np
import time
import psycopg2
import requests
import logging
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer

# === Load config t·ª´ file .env ===
load_dotenv()

# === SBERT model for embedding ===
embedding_model = SentenceTransformer("keepitreal/vietnamese-sbert")

# === API Gemini Config ===
GEMINI_API_KEY = os.getenv("GOOGLE_API_KEY")
gemini_api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"

# === PostgreSQL config ===
PG_HOST = os.getenv("DB_HOST")
PG_PORT = os.getenv("DB_PORT", "5432")
PG_NAME = os.getenv("DB_NAME")
PG_USER = os.getenv("DB_USER")
PG_PASSWORD = os.getenv("DB_PASSWORD")

# === C·∫•u h√¨nh logging ƒë·ªÉ ghi l·∫°i l·ªói ===
logging.basicConfig(level=logging.DEBUG, filename="errors.log", filemode="w")

# === H√†m g·ªçi API Gemini ƒë·ªÉ sinh t√≥m t·∫Øt ===
def generate_summary_with_gemini(title, genres, description):
    prompt = f"""
    B·∫°n l√† m·ªôt AI chuy√™n ƒë√°nh gi√° v√† t√≥m t·∫Øt truy·ªán ch·ªØ. V·ªõi ƒë·∫ßu v√†o l√†:
    - Ti√™u ƒë·ªÅ: {title}
    - Th·ªÉ lo·∫°i: {genres}
    - N·ªôi dung: {description}

    H√£y vi·∫øt m·ªôt ƒëo·∫°n t·ª´ 100-150 t·ª´:
    1. T√≥m t·∫Øt n·ªôi dung
    2. ƒê∆∞a ra c·∫£m nh·∫≠n ho·∫∑c nh·∫≠n x√©t t·ªïng quan
    3. Vi·∫øt m·∫°ch l·∫°c, tr√¥i ch·∫£y b·∫±ng ti·∫øng Vi·ªát
    """

    payload = {
        "contents": [
            {
                "parts": [{"text": prompt}]
            }
        ]
    }

    headers = {
        "Content-Type": "application/json"
    }

    try:
        response = requests.post(gemini_api_url, headers=headers, data=json.dumps(payload), timeout=30)
        response.raise_for_status()
        response_data = response.json()

        # ‚úÖ L·∫•y ƒë√∫ng t√≥m t·∫Øt t·ª´ ph·∫£n h·ªìi
        summary = response_data.get("candidates", [])[0]["content"]["parts"][0]["text"]
        return summary.strip()

    except (KeyError, IndexError):
        print(f"‚ùå API Gemini kh√¥ng tr·∫£ v·ªÅ tr∆∞·ªùng 'content' cho truy·ªán: {title}")
        logging.error(f"Kh√¥ng c√≥ content trong ph·∫£n h·ªìi Gemini cho truy·ªán: {title}\nPh·∫£n h·ªìi: {json.dumps(response_data, ensure_ascii=False)}")
        return ""
    except requests.exceptions.Timeout:
        print(f"‚ùå Qu√° th·ªùi gian ch·ªù ph·∫£n h·ªìi t·ª´ Gemini API cho truy·ªán: {title}")
        logging.error(f"Timeout khi g·ªçi Gemini API cho truy·ªán: {title}")
        return ""
    except requests.exceptions.RequestException as e:
        print(f"‚ùå L·ªói khi g·ªçi Gemini API cho truy·ªán: {title} - {e}")
        logging.error(f"L·ªói khi g·ªçi Gemini API cho truy·ªán {title}: {str(e)}")
        return ""

# === K·∫øt n·ªëi ƒë·∫øn c∆° s·ªü d·ªØ li·ªáu PostgreSQL ===
conn = psycopg2.connect(
    host=PG_HOST,
    port=PG_PORT,
    dbname=PG_NAME,
    user=PG_USER,
    password=PG_PASSWORD
)
cursor = conn.cursor()

# === L·∫•y d·ªØ li·ªáu t·ª´ b·∫£ng stories ===
cursor.execute("""SELECT id, title, description, genres FROM public."Story" WHERE summary IS NULL OR summary = '';""")
rows = cursor.fetchall()

metadata_list = []
embedding_texts = []

# === X·ª≠ l√Ω t·ª´ng truy·ªán ===
for row in rows:
    id, title, description, genres_raw = row
    genres = ", ".join(genres_raw) if isinstance(genres_raw, list) else genres_raw or ""

    try:
        summary = generate_summary_with_gemini(title, genres, description)
    except Exception as e:
        print(f"‚ùå L·ªói khi sinh t√≥m t·∫Øt cho truy·ªán: {title} _ {e}")
        summary = ""

    if summary:
        print(f"‚úÖ T√≥m t·∫Øt cho truy·ªán {title}: {summary}")
    else:
        print(f"‚ùå Kh√¥ng c√≥ t√≥m t·∫Øt cho truy·ªán {title}")

    # metadata_list.append({
    #     "id": id,
    #     "title": title,
    #     "genres": genres,
    #     "description": description,
    #     "summary": summary
    # })

    # C·∫≠p nh·∫≠t t√≥m t·∫Øt v√†o c∆° s·ªü d·ªØ li·ªáu
    try:
        cursor.execute("""
            UPDATE public."Story"
            SET summary = %s
            WHERE id = %s;
        """, (summary, id))
        conn.commit()
        print(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t t√≥m t·∫Øt cho truy·ªán ID: {id}")
    except Exception as e:
        print(f"‚ùå L·ªói khi c·∫≠p nh·∫≠t t√≥m t·∫Øt v√†o DB cho truy·ªán ID: {id} - {e}")
        logging.error(f"L·ªói khi c·∫≠p nh·∫≠t t√≥m t·∫Øt v√†o DB cho truy·ªán ID: {id} - {e}")

    #embedding_text = f"{id}. {title}. {genres}. {description}. {summary}"
    #embedding_texts.append(embedding_text)

# === T·∫°o embedding ===
print("üîÑ ƒêang t·∫°o embeddings...")
#embeddings = embedding_model.encode(embedding_texts, convert_to_numpy=True, show_progress_bar=True)

# === Build FAISS index ===
# dim = embeddings.shape[1]
# index = faiss.IndexFlatL2(dim)
# index.add(np.array(embeddings).astype("float32"))

# === L∆∞u index & metadata ===
# faiss.write_index(index, "story_faiss.index")

# with open("stories_embeddings.pkl", "wb") as f:
#     pickle.dump(metadata_list, f)

print("‚úÖ ƒê√£ l∆∞u story_faiss.index v√† stories_embeddings.pkl ch·ª©a AI reply + metadata.")

# === ƒê√≥ng k·∫øt n·ªëi DB ===
cursor.close()
conn.close()
